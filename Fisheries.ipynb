{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Flatten, Conv2D, MaxPooling2D, GlobalMaxPool2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.core import Activation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fisheries Competition\n",
    "\n",
    "To demonstrate my understanding of the fast.ai course I'm going to try and solve the key parts of Lesson 7's fisheries challenge. \n",
    "\n",
    "https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/\n",
    "\n",
    "I'm also going to use the bounding boxes that can be found: \n",
    "\n",
    "https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/discussion/25902\n",
    "\n",
    "But the first step is to understand the data:\n",
    "\n",
    "It's setup in a nice way for keras, with the training data extracting into a set of folders, each folder containing a list of jpgs. So we can easily use the Image Data Generator from https://keras.io/preprocessing/image/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAG', 'OTHER', '.DS_Store', 'SHARK', 'NoF', 'YFT', 'BET', 'DOL', 'ALB']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from shutil import move , copy\n",
    "from os.path import join\n",
    "from os.path import split\n",
    "path = join('data')\n",
    "classes = os.listdir(join(path, 'train'))\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any hidden folders in the listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAG', 'OTHER', 'SHARK', 'NoF', 'YFT', 'BET', 'DOL', 'ALB']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [c for c in classes if c[0] != '.']\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to split data into train, valid and sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import glob\n",
    "\n",
    "valid_ratio = 0.2\n",
    "num_sample_images = 10\n",
    "valid_path = join(path, 'valid')\n",
    "if not os.path.exists(valid_path):\n",
    "    os.makedirs(valid_path)\n",
    "\n",
    "    for c in classes:\n",
    "        cl_valid_path = join(valid_path, c)\n",
    "        cl_train_path = join(path, 'train', c)\n",
    "        cl_sample_path = join(path, 'sample', c)\n",
    "        files = glob.glob(join(cl_train_path, '*.jpg'))\n",
    "        os.makedirs(cl_valid_path)\n",
    "        valid = choice(files, int(np.floor(0.2*len(files))), replace=False)\n",
    "        [move(v, join(cl_valid_path, split(v)[1])) for v in valid]\n",
    "        # We don't want the sample to contain the validation data, so redo the glob after moving. \n",
    "        files = glob.glob(join(cl_train_path, '*.jpg'))\n",
    "        os.makedirs(cl_sample_path)\n",
    "        sample = choice(files, num_sample_images, replace=False)\n",
    "        [copy(s, join(cl_sample_path, split(s)[1])) for s in sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAG', 'OTHER', 'SHARK', 'NoF', 'YFT', 'BET', 'DOL', 'ALB']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAG', 'OTHER', 'SHARK', 'NoF', 'YFT', 'BET', 'DOL', 'ALB']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(join(path,'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3025 images belonging to 8 classes.\n",
      "Found 752 images belonging to 8 classes.\n",
      "Found 80 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "bs = 1\n",
    "gen = ImageDataGenerator()\n",
    "train_gen = gen.flow_from_directory(join(path,'train'), batch_size=bs, shuffle=False)\n",
    "valid_gen = gen.flow_from_directory(join(path,'valid'), batch_size=bs, shuffle=False)\n",
    "sample_gen = gen.flow_from_directory(join(path,'sample'), batch_size=bs, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "\n",
    "def save_generator(gen, data_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    Save the output from a generator without loading all images into memory. \n",
    "    \n",
    "    Does not return anything, instead writes data to disk.\n",
    "    \n",
    "    :gen: A Keras ImageDataGenerator object\n",
    "    :data_dir: The folder name to store the bcolz array representing the features in. \n",
    "    :labels_dir: The folder name to store the bcolz array representing the labels in.\n",
    "    :mode: the write mode. Set to 'a' for append, set to 'w' to overwrite existing data and 'r' to read only. \n",
    "    \n",
    "    \"\"\"\n",
    "    for directory in [data_dir, labels_dir]:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    \n",
    "    num_samples = gen.samples\n",
    "    \n",
    "    d,l = gen.__next__()\n",
    "    \n",
    "    data = bcolz.carray(d, rootdir=data_dir, mode='w')\n",
    "    labels = bcolz.carray(l, rootdir=labels_dir, mode='w')\n",
    "\n",
    "    for i in tqdm(range(num_samples-1)):\n",
    "        d, l = gen.__next__()\n",
    "        data.append(d)\n",
    "        labels.append(l)\n",
    "    data.flush()\n",
    "    labels.flush()\n",
    "\n",
    "\n",
    "trn_data = join('bdat','train','data')\n",
    "trn_label = join('bdat','train','label')\n",
    "val_data = join('bdat','valid','data')\n",
    "val_label = join('bdat','valid','label')\n",
    "samp_data = join('bdat','sample','data')\n",
    "samp_label = join('bdat','sample','label')\n",
    "\n",
    "#save_generator(train_gen, trn_data, trn_label)\n",
    "#save_generator(valid_gen, val_data, val_label)\n",
    "#save_generator(sample_gen, samp_data, samp_label)\n",
    "\n",
    "data = bcolz.open(trn_data)\n",
    "labels = bcolz.open(trn_label)\n",
    "val_data = bcolz.open(val_data)\n",
    "val_labels = bcolz.open(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3025, 256, 256, 3)\n",
      "(3025, 8)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the simplest model possible to check data loading, Simple Conv net. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out the shape of the data... (actually this is the default shape due to the ImageGenerator). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 254, 254, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 59, 59, 8)         1160      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 3,928.0\n",
      "Trainable params: 3,928.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple = Sequential([\n",
    "    InputLayer((256,256,3)),\n",
    "    Conv2D(16,(3,3), activation='relu'),\n",
    "    MaxPooling2D(4),\n",
    "    Conv2D(16, (3,3), activation='relu'),\n",
    "    Conv2D(8, (3,3), activation='relu'),\n",
    "    GlobalMaxPool2D()\n",
    "  ])\n",
    "simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "simple.fit(data, labels, batch_size=16, validation_data=(val_data,val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ok, lets try using a pretrained inception net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('blah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "\n",
    "xModel = Xception(include_top=False, input_shape=(256,256,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_predictions(model, data, rootdir, batch_size):\n",
    "    \"\"\"\n",
    "    This function will use BColz to save the predictions from a model. This is useful when you want to get the features from a\n",
    "    pretrained net and build something ontop of it without re-evaluating the network every time. \n",
    "    \n",
    "    This function does not return anything and writes stuff to disk.\n",
    "    \n",
    "    :model: A keras model.\n",
    "    :data: A Numpy dataframe, it is assumed that the first index is the batch index. \n",
    "    :roodir: The directory to store the bcolz data\n",
    "    :batchsize: The number of samples to run. Will depend upon your hardware. \n",
    "    \"\"\"\n",
    "    output = bcolz.carray(model.predict(data[0:batch_size]), rootdir=rootdir, mode='w')\n",
    "    \n",
    "    for i in tqdm(range(batch_size, data.shape[0], batch_size)):\n",
    "        end = i+batch_size if i+batch_size < data.shape[0] else data.shape[0]\n",
    "        output.append(model.predict(data[i:end]))\n",
    "    output.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1512/1512 [04:37<00:00,  6.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#os.makedirs(join('bdat','pretrained','data'))\n",
    "save_predictions(xModel, data, join('bdat','pretrained','data'), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [01:09<00:00,  5.61it/s]\n"
     ]
    }
   ],
   "source": [
    "save_predictions(xModel, val_data, join('bdat','pretrained','valdata'), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xCdata = bcolz.open(join('bdat','pretrained','data'))\n",
    "xValdata = bcolz.open(join('bdat','pretrained','valdata'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xCdata = xModel.predict(data[:],verbose=1, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xValdata = xModel.predict(val_data, verbose=1, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When running on a cloud server like FloydHub or Crestle I found that I needed to load the data into RAM instead of using BColz. I think this is because these services are using network drives (which are much slower than SSD's). The following code loads the entire contents of the BCOLZ data into an inmemory array. If you are on an SSD you probably don't need this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comment out if you are reading off an SSD.\n",
    "xCdata = xCdata[:]\n",
    "xValdata = xValdata[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_top = Sequential([\n",
    "    InputLayer((8,8,2048)),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(8, activation='softmax')\n",
    "])\n",
    "pretrained_top.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3025 samples, validate on 752 samples\n",
      "Epoch 1/10\n",
      "3025/3025 [==============================] - 16s - loss: 4.5558 - acc: 0.3511 - val_loss: 3.2400 - val_acc: 0.4295\n",
      "Epoch 2/10\n",
      "3025/3025 [==============================] - 16s - loss: 2.6773 - acc: 0.4585 - val_loss: 2.2840 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "3025/3025 [==============================] - 15s - loss: 1.9335 - acc: 0.5296 - val_loss: 1.8558 - val_acc: 0.5785\n",
      "Epoch 4/10\n",
      "3025/3025 [==============================] - 15s - loss: 1.5498 - acc: 0.6076 - val_loss: 1.5163 - val_acc: 0.5931\n",
      "Epoch 5/10\n",
      "3025/3025 [==============================] - 16s - loss: 1.2754 - acc: 0.6453 - val_loss: 1.2765 - val_acc: 0.6370\n",
      "Epoch 6/10\n",
      "3025/3025 [==============================] - 16s - loss: 1.0632 - acc: 0.6869 - val_loss: 1.2398 - val_acc: 0.6516\n",
      "Epoch 7/10\n",
      "3025/3025 [==============================] - 16s - loss: 0.8807 - acc: 0.7210 - val_loss: 1.0191 - val_acc: 0.6888\n",
      "Epoch 8/10\n",
      "3025/3025 [==============================] - 16s - loss: 0.8093 - acc: 0.7455 - val_loss: 0.9728 - val_acc: 0.6888\n",
      "Epoch 9/10\n",
      "3025/3025 [==============================] - 16s - loss: 0.7511 - acc: 0.7640 - val_loss: 0.9025 - val_acc: 0.7274\n",
      "Epoch 10/10\n",
      "3025/3025 [==============================] - 16s - loss: 0.6754 - acc: 0.7917 - val_loss: 0.8367 - val_acc: 0.7473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bc48e5fd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_top.fit(xCdata[:], labels, validation_data=(xValdata, val_labels), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like we've gotten 74% val accuracy with this simple model. Let's try doing a fully convolutional model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 8)           147464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 8)           32        \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 147,496\n",
      "Trainable params: 147,480\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_top = Sequential([InputLayer((8,8,2048)),\n",
    "                      Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "                       BatchNormalization(),\n",
    "                      GlobalAveragePooling2D(),\n",
    "                       Activation('softmax')\n",
    "                      ])\n",
    "conv_top.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "conv_top.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3025 samples, validate on 752 samples\n",
      "Epoch 1/10\n",
      "3025/3025 [==============================] - 17s - loss: 1.7931 - acc: 0.4298 - val_loss: 1.2984 - val_acc: 0.5944\n",
      "Epoch 2/10\n",
      "3025/3025 [==============================] - 17s - loss: 1.5116 - acc: 0.6020 - val_loss: 1.2050 - val_acc: 0.6968\n",
      "Epoch 3/10\n",
      "3025/3025 [==============================] - 18s - loss: 1.3537 - acc: 0.7051 - val_loss: 1.1831 - val_acc: 0.7593\n",
      "Epoch 4/10\n",
      "3025/3025 [==============================] - 18s - loss: 1.2588 - acc: 0.7431 - val_loss: 1.2637 - val_acc: 0.7407\n",
      "Epoch 5/10\n",
      "3025/3025 [==============================] - 18s - loss: 1.1767 - acc: 0.7858 - val_loss: 1.0958 - val_acc: 0.7899\n",
      "Epoch 6/10\n",
      "3025/3025 [==============================] - 18s - loss: 1.1004 - acc: 0.8298 - val_loss: 1.0727 - val_acc: 0.7753\n",
      "Epoch 7/10\n",
      "3025/3025 [==============================] - 18s - loss: 1.0469 - acc: 0.8344 - val_loss: 1.0826 - val_acc: 0.7819\n",
      "Epoch 8/10\n",
      "3025/3025 [==============================] - 18s - loss: 0.9860 - acc: 0.8618 - val_loss: 1.1641 - val_acc: 0.8178\n",
      "Epoch 9/10\n",
      "3025/3025 [==============================] - 18s - loss: 0.9449 - acc: 0.8764 - val_loss: 1.0323 - val_acc: 0.8191\n",
      "Epoch 10/10\n",
      "3025/3025 [==============================] - 17s - loss: 0.8922 - acc: 0.8783 - val_loss: 1.1278 - val_acc: 0.8112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bc5b56f60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_top.fit(xCdata, labels, validation_data=(xValdata, val_labels), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, that got 81% validation accuracy.... \n",
    "\n",
    "I couldn't get Jeremy's Keras.backend.Function to work, so I've just created a new model and predicted on it. The output is the same. \n",
    "Below I'm plotting an overlay of the average pooling layer for the predicted class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, can we visualise the parts of the pictures that are important to this conv net? \n",
    "\n",
    "Jeremy constructs a function that takes in an image and returns a pixel value... this requires an end to end model... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 8, 8, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 8)           147464    \n",
      "=================================================================\n",
      "Total params: 21,008,944\n",
      "Trainable params: 20,954,416\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_layers = [xModel, conv_top.layers[1]]\n",
    "\n",
    "full_model = Sequential(full_layers)\n",
    "full_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "full_model.summary()\n",
    "\n",
    "pred = full_model.predict(data[0][np.newaxis,:,:,:])[0]\n",
    "pred.shape\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "import scipy.misc\n",
    "\n",
    "i = np.argmax(conv_top.predict(xCdata[0][np.newaxis,:,:,:]))\n",
    "pl.figure()\n",
    "pl.imshow(data[0])\n",
    "pl.imshow(scipy.misc.imresize(pred[i], (240,240), interp='nearest'), alpha=0.5)\n",
    "pl.title(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the model is really using spatial cues from the image instead of actually looking for fish! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
